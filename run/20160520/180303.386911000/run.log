2016-05-20 18:03:05.213200 # on dhcp-169-233-138-157.cruznet.ucsc.edu: deepdive do team_mention
2016-05-20 18:03:05.213559 # run/20160520/180303.386911000/plan.sh
2016-05-20 18:03:05.213595 # execution plan for data/team_mention
2016-05-20 18:03:05.213624 
2016-05-20 18:03:05.213645 : ## process/init/app ##########################################################
2016-05-20 18:03:05.213666 : # Done: 2016-05-20T15:47:44-0700 (2h 15m 19s ago)
2016-05-20 18:03:05.213686 : process/init/app/run.sh
2016-05-20 18:03:05.213705 : mark_done process/init/app
2016-05-20 18:03:05.213723 : ##############################################################################
2016-05-20 18:03:05.213744 
2016-05-20 18:03:05.213767 ## process/init/relation/articles ############################################
2016-05-20 18:03:05.213788 # Done: 2016-05-20T15:47:44-0700 (2h 15m 19s ago)
2016-05-20 18:03:05.213808 process/init/relation/articles/run.sh
2016-05-20 18:03:05.213830 ++ dirname process/init/relation/articles/run.sh
2016-05-20 18:03:05.213882 + cd process/init/relation/articles
2016-05-20 18:03:05.213911 + export DEEPDIVE_CURRENT_PROCESS_NAME=process/init/relation/articles
2016-05-20 18:03:05.213931 + DEEPDIVE_CURRENT_PROCESS_NAME=process/init/relation/articles
2016-05-20 18:03:05.213952 + deepdive create table articles
2016-05-20 18:03:05.438217 CREATE TABLE
2016-05-20 18:03:05.439143 + deepdive load articles
2016-05-20 18:03:05.545558 Loading articles from input/articles.tsv.sh (tsv format)
2016-05-20 18:03:05.557597 ERROR: Missing /Users/emerson/Documents/Github/deepdive/examples/Coach_NBA/input/signalmedia/signalmedia-1m.jsonl
2016-05-20 18:03:05.557662 # Please Download it from http://research.signalmedia.co/newsir16/signal-dataset.html
2016-05-20 18:03:05.557688 
2016-05-20 18:03:05.557710 # Alternatively, use our sampled data by running:
2016-05-20 18:03:05.557731 deepdive load articles input/articles-100.tsv.bz2
2016-05-20 18:03:05.557751 
2016-05-20 18:03:05.557773 # Or, skipping all NLP markup processes by running:
2016-05-20 18:03:05.557825 deepdive create table sentences
2016-05-20 18:03:05.557864 deepdive load sentences
2016-05-20 18:03:05.557888 deepdive mark done sentences
2016-05-20 18:03:05.599393 COPY 0
2016-05-20 18:03:05.636179 mark_done process/init/relation/articles
2016-05-20 18:03:05.659669 ##############################################################################
2016-05-20 18:03:05.659793 
2016-05-20 18:03:05.659850 ## data/articles #############################################################
2016-05-20 18:03:05.659881 # Done: 2016-05-20T15:49:44-0700 (2h 13m 19s ago)
2016-05-20 18:03:05.659908 # no-op
2016-05-20 18:03:05.659937 mark_done data/articles
2016-05-20 18:03:05.683406 ##############################################################################
2016-05-20 18:03:05.683473 
2016-05-20 18:03:05.683499 ## process/ext_sentences_by_nlp_markup #######################################
2016-05-20 18:03:05.683520 # Done: 2016-05-20T15:53:58-0700 (2h 9m 5s ago)
2016-05-20 18:03:05.683540 process/ext_sentences_by_nlp_markup/run.sh
2016-05-20 18:03:05.692417 ++ dirname process/ext_sentences_by_nlp_markup/run.sh
2016-05-20 18:03:05.698717 + cd process/ext_sentences_by_nlp_markup
2016-05-20 18:03:05.698810 + export DEEPDIVE_CURRENT_PROCESS_NAME=process/ext_sentences_by_nlp_markup
2016-05-20 18:03:05.698847 + DEEPDIVE_CURRENT_PROCESS_NAME=process/ext_sentences_by_nlp_markup
2016-05-20 18:03:05.698872 + export DEEPDIVE_LOAD_FORMAT=tsv
2016-05-20 18:03:05.698893 + DEEPDIVE_LOAD_FORMAT=tsv
2016-05-20 18:03:05.698939 + deepdive compute execute 'input_sql= SELECT R0.id AS "articles.R0.id", R0.content AS "articles.R0.content"
2016-05-20 18:03:05.698964 FROM articles R0
2016-05-20 18:03:05.698987         
2016-05-20 18:03:05.699009           ' 'command="$DEEPDIVE_APP"/udf/nlp_markup.sh' output_relation=sentences
2016-05-20 18:03:05.789368 Executing with the following configuration:
2016-05-20 18:03:05.789417  DEEPDIVE_NUM_PROCESSES=3
2016-05-20 18:03:05.789434  DEEPDIVE_NUM_PARALLEL_UNLOADS=1
2016-05-20 18:03:05.789455  DEEPDIVE_NUM_PARALLEL_LOADS=1
2016-05-20 18:03:05.789501  output_relation_tmp=dd_tmp_sentences
2016-05-20 18:03:05.789526 
2016-05-20 18:03:06.001981 CREATE TABLE
2016-05-20 18:03:06.106963 CREATE TABLE
2016-05-20 18:03:06.298713 unloading to feed_processes-1: ' SELECT R0.id AS "articles.R0.id", R0.content AS "articles.R0.content"
2016-05-20 18:03:06.298788 FROM articles R0
2016-05-20 18:03:06.298825         
2016-05-20 18:03:06.298857           '
2016-05-20 18:03:06.324186 Loading dd_tmp_sentences from output_computed-1 (tsv format)
2016-05-20 18:03:07.682372 Parsing with max_len=100
2016-05-20 18:03:07.688386 Parsing with max_len=100
2016-05-20 18:03:07.695687 Parsing with max_len=100
2016-05-20 18:03:07.947925 Adding annotator tokenize
2016-05-20 18:03:07.951666 Adding annotator tokenize
2016-05-20 18:03:07.955904 TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
2016-05-20 18:03:07.960619 TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
2016-05-20 18:03:07.991554 Adding annotator cleanxml
2016-05-20 18:03:08.005278 Adding annotator cleanxml
2016-05-20 18:03:08.008300 Adding annotator tokenize
2016-05-20 18:03:08.018745 TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
2016-05-20 18:03:08.026191 Adding annotator cleanxml
2016-05-20 18:03:08.046214 Adding annotator ssplit
2016-05-20 18:03:08.050456 Adding annotator ssplit
2016-05-20 18:03:08.053173 Adding annotator pos
2016-05-20 18:03:08.054628 Adding annotator pos
2016-05-20 18:03:08.071925 Adding annotator ssplit
2016-05-20 18:03:08.073751 Adding annotator pos
2016-05-20 18:03:11.541421 Reading POS tagger model from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... Reading POS tagger model from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... Reading POS tagger model from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [3.4 sec].
2016-05-20 18:03:11.542034 Adding annotator lemma
2016-05-20 18:03:11.548488 Adding annotator ner
2016-05-20 18:03:11.703271 done [3.6 sec].
2016-05-20 18:03:11.703423 Adding annotator lemma
2016-05-20 18:03:11.722442 Adding annotator ner
2016-05-20 18:03:11.813489 done [3.7 sec].
2016-05-20 18:03:11.813656 Adding annotator lemma
2016-05-20 18:03:11.814719 Adding annotator ner
2016-05-20 18:03:21.931140 Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [10.0 sec].
2016-05-20 18:03:21.938710 Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [10.1 sec].
2016-05-20 18:03:22.007427 Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [9.9 sec].
2016-05-20 18:03:26.607145 Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [4.7 sec].
2016-05-20 18:03:26.700366 Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [4.8 sec].
2016-05-20 18:03:29.893489 Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [7.9 sec].
2016-05-20 18:03:34.578576 Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [8.0 sec].
2016-05-20 18:03:34.583830 done [7.9 sec].
2016-05-20 18:03:34.584365 sutime.binder.1.
2016-05-20 18:03:34.584419 Initializing JollyDayHoliday for sutime with classpath:edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml
2016-05-20 18:03:34.586609 sutime.binder.1.
2016-05-20 18:03:34.586676 Initializing JollyDayHoliday for sutime with classpath:edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml
2016-05-20 18:03:34.915223 done [5.0 sec].
2016-05-20 18:03:34.924680 sutime.binder.1.
2016-05-20 18:03:34.924775 Initializing JollyDayHoliday for sutime with classpath:edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml
2016-05-20 18:03:35.924333 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/defs.sutime.txt
2016-05-20 18:03:35.942951 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/defs.sutime.txt
2016-05-20 18:03:35.983282 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/defs.sutime.txt
2016-05-20 18:03:36.112597 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.sutime.txt
2016-05-20 18:03:36.127160 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.sutime.txt
2016-05-20 18:03:36.185082 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.sutime.txt
2016-05-20 18:03:37.511086 May 20, 2016 6:03:37 PM edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor appendRules
2016-05-20 18:03:37.511154 信息: Ignoring inactive rule: null
2016-05-20 18:03:37.512213 May 20, 2016 6:03:37 PM edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor appendRules
2016-05-20 18:03:37.512275 信息: Ignoring inactive rule: temporal-composite-8:ranges
2016-05-20 18:03:37.512426 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.holidays.sutime.txt
2016-05-20 18:03:37.521007 Adding annotator parse
2016-05-20 18:03:37.568430 Loading parser from serialized file edu/stanford/nlp/models/srparser/englishSR.ser.gz ...May 20, 2016 6:03:37 PM edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor appendRules
2016-05-20 18:03:37.568533 信息: Ignoring inactive rule: null
2016-05-20 18:03:37.569784 May 20, 2016 6:03:37 PM edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor appendRules
2016-05-20 18:03:37.569856 信息: Ignoring inactive rule: temporal-composite-8:ranges
2016-05-20 18:03:37.570134 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.holidays.sutime.txt
2016-05-20 18:03:37.577375 Adding annotator parse
2016-05-20 18:03:37.699868 Loading parser from serialized file edu/stanford/nlp/models/srparser/englishSR.ser.gz ...May 20, 2016 6:03:37 PM edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor appendRules
2016-05-20 18:03:37.699942 信息: Ignoring inactive rule: null
2016-05-20 18:03:37.701029 May 20, 2016 6:03:37 PM edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor appendRules
2016-05-20 18:03:37.701108 信息: Ignoring inactive rule: temporal-composite-8:ranges
2016-05-20 18:03:37.701444 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.holidays.sutime.txt
2016-05-20 18:03:37.715092 Adding annotator parse
2016-05-20 18:04:30.669239 Loading parser from serialized file edu/stanford/nlp/models/srparser/englishSR.ser.gz ...done [53.1 sec].
2016-05-20 18:04:31.735376 done [54.1 sec].
2016-05-20 18:04:32.659807 done [54.9 sec].
2016-05-20 18:04:32.903536 COPY 0
2016-05-20 18:04:32.928505 Replacing sentences with dd_tmp_sentences
2016-05-20 18:04:33.068710 DROP TABLE
2016-05-20 18:04:33.175623 ALTER TABLE
2016-05-20 18:04:33.257010 ALTER TABLE
2016-05-20 18:04:33.353933 DROP TABLE
2016-05-20 18:04:33.387836 ANALYZE
2016-05-20 18:04:33.401870 mark_done process/ext_sentences_by_nlp_markup
2016-05-20 18:04:33.427602 ##############################################################################
2016-05-20 18:04:33.427651 
2016-05-20 18:04:33.427690 ## data/sentences ############################################################
2016-05-20 18:04:33.427713 # Done: 2016-05-20T15:53:59-0700 (2h 9m 4s ago)
2016-05-20 18:04:33.427751 # no-op
2016-05-20 18:04:33.427862 mark_done data/sentences
2016-05-20 18:04:33.452394 ##############################################################################
2016-05-20 18:04:33.452528 
2016-05-20 18:04:33.452575 ## process/ext_team_mention_by_map_team_mention ##############################
2016-05-20 18:04:33.452637 # Done: N/A
2016-05-20 18:04:33.452682 process/ext_team_mention_by_map_team_mention/run.sh
2016-05-20 18:04:33.480166 ++ dirname process/ext_team_mention_by_map_team_mention/run.sh
2016-05-20 18:04:33.483404 + cd process/ext_team_mention_by_map_team_mention
2016-05-20 18:04:33.483488 + export DEEPDIVE_CURRENT_PROCESS_NAME=process/ext_team_mention_by_map_team_mention
2016-05-20 18:04:33.483537 + DEEPDIVE_CURRENT_PROCESS_NAME=process/ext_team_mention_by_map_team_mention
2016-05-20 18:04:33.483585 + export DEEPDIVE_LOAD_FORMAT=tsv
2016-05-20 18:04:33.483616 + DEEPDIVE_LOAD_FORMAT=tsv
2016-05-20 18:04:33.483642 + deepdive compute execute 'input_sql= SELECT R0.doc_id AS "sentences.R0.doc_id", R0.sentence_index AS "sentences.R0.sentence_index", R0.tokens AS "sentences.R0.tokens", R0.ner_tags AS "sentences.R0.ner_tags"
2016-05-20 18:04:33.483665 FROM sentences R0
2016-05-20 18:04:33.483687         
2016-05-20 18:04:33.483711           ' 'command="$DEEPDIVE_APP"/udf/map_team_mention.py' output_relation=team_mention
2016-05-20 18:04:33.567919 Executing with the following configuration:
2016-05-20 18:04:33.567970  DEEPDIVE_NUM_PROCESSES=3
2016-05-20 18:04:33.567989  DEEPDIVE_NUM_PARALLEL_UNLOADS=1
2016-05-20 18:04:33.568011  DEEPDIVE_NUM_PARALLEL_LOADS=1
2016-05-20 18:04:33.568068  output_relation_tmp=dd_tmp_team_mention
2016-05-20 18:04:33.568093 
2016-05-20 18:04:33.746213 [ERROR] team_mention: No such table defined in schema
